import cv2
import numpy as np
import os
from insightface.app import FaceAnalysis
from collections import deque
import time

# ================= CONFIGURATION =================
# Camera Settings
CAMERA_ID = 0
FRAME_WIDTH = 1280
FRAME_HEIGHT = 720

# Model Settings
MODEL_NAME = 'buffalo_l'  # Most accurate model
CTX_ID = 0  # 0 = GPU, -1 = CPU

# Detection Settings - OPTIMIZED FOR 60 FPS + HIGH ACCURACY
DET_SIZE = (1280, 1280)  # High resolution maintained
DET_THRESH = 0.45  # Balanced threshold

# Recognition Settings
RECOGNITION_THRESHOLD = 0.38  # Lower for better accuracy (increased sensitivity)
SMOOTH_FRAMES = 3  # Reduced for faster response

# Performance Settings - 60 FPS OPTIMIZED
USE_MULTI_SCALE = True  # Keep multi-scale for accuracy
MAX_FACES_TO_PROCESS = 100
ENABLE_FACE_TRACKING = True  # Track faces across frames (huge speed boost)

# Advanced optimizations
DETECTION_INTERVAL = 3  # Run full detection every N frames, track in between
PREPROCESS_EVERY_N_FRAMES = 2  # Only preprocess every Nth frame
# =================================================

dll_path = r"C:\Users\D.S.Manoj\Desktop\robot 1\venv\Lib\site-packages\onnxruntime\capi"
os.environ["PATH"] += os.pathsep + dll_path
if hasattr(os, 'add_dll_directory'):
    os.add_dll_directory(dll_path)


class FaceTracker:
    """Lightweight face tracker for inter-frame tracking using KCF"""
    def __init__(self):
        self.tracker = None
        self.bbox = None
        self.initialized = False
        self.face_data = None
        self.frames_since_update = 0
        
    def init(self, frame, bbox, face_data):
        """Initialize tracker with first detection"""
        self.bbox = bbox
        self.face_data = face_data
        self.tracker = cv2.legacy.TrackerKCF_create()  # Using legacy for compatibility
        
        # Convert bbox to x, y, w, h format
        x1, y1, x2, y2 = bbox.astype(int)
        w, h = x2 - x1, y2 - y1
        self.tracker.init(frame, (x1, y1, w, h))
        self.initialized = True
        self.frames_since_update = 0
        
    def update(self, frame):
        """Update tracker position"""
        if not self.initialized:
            return False, None
        
        success, bbox = self.tracker.update(frame)
        self.frames_since_update += 1
        
        if success:
            x, y, w, h = bbox
            self.bbox = np.array([x, y, x + w, y + h])
            return True, self.bbox
        
        return False, None


class OptimizedFaceTracker:
    def __init__(self):
        print("ü§ñ Initializing Ultra-High-Speed Face Tracker (No CuPy)...")
        
        # Initialize FaceAnalysis with optimized settings
        self.app = FaceAnalysis(
            name=MODEL_NAME,
            providers=['CUDAExecutionProvider', 'CPUExecutionProvider']
        )
        self.app.prepare(ctx_id=CTX_ID, det_size=DET_SIZE, det_thresh=DET_THRESH)
        
        # Target storage
        self.target_embeddings = []
        self.target_name = "Unknown"
        
        # Performance tracking
        self.frame_count = 0
        self.fps_buffer = deque(maxlen=30)
        self.last_time = time.time()
        
        # Face tracking
        self.face_trackers = []
        self.last_full_detection_frame = 0
        
        # Cached preprocessed frame
        self.preprocessed_cache = None
        self.last_preprocessed_frame = -1
        
        print("‚úÖ AI Brain Initialized!")
        print("üöÄ 60 FPS Optimization Mode Active!")
    
    def load_target(self, image_path):
        """Load target with enhanced multi-angle embeddings for better accuracy"""
        if not os.path.exists(image_path):
            print("‚ö†Ô∏è  Target image not found.")
            return False
        
        print(f"üéØ Loading target from {image_path}...")
        img_target = cv2.imread(image_path)
        
        if img_target is None:
            print("‚ùå Could not read target image.")
            return False
        
        embeddings_list = []
        
        # Original image
        faces = self.app.get(img_target)
        if len(faces) > 0:
            embeddings_list.append(faces[0].embedding)
        
        # Flipped version (mirror)
        img_flipped = cv2.flip(img_target, 1)
        faces_flipped = self.app.get(img_flipped)
        if len(faces_flipped) > 0:
            embeddings_list.append(faces_flipped[0].embedding)
        
        # Brightness variations (more for accuracy)
        for gamma in [0.6, 0.7, 0.8, 1.0, 1.2, 1.3, 1.4]:
            adjusted = self.adjust_gamma(img_target, gamma)
            faces_adj = self.app.get(adjusted)
            if len(faces_adj) > 0:
                embeddings_list.append(faces_adj[0].embedding)
        
        # Rotation variations for different head angles
        for angle in [-20, -10, -5, 5, 10, 20]:
            rotated = self.rotate_image(img_target, angle)
            faces_rot = self.app.get(rotated)
            if len(faces_rot) > 0:
                embeddings_list.append(faces_rot[0].embedding)
        
        # Contrast adjustments
        for alpha in [0.7, 0.9, 1.1, 1.3]:
            contrasted = cv2.convertScaleAbs(img_target, alpha=alpha, beta=0)
            faces_con = self.app.get(contrasted)
            if len(faces_con) > 0:
                embeddings_list.append(faces_con[0].embedding)
        
        # Blur variations (to match motion blur in real-time)
        for ksize in [3, 5]:
            blurred = cv2.GaussianBlur(img_target, (ksize, ksize), 0)
            faces_blur = self.app.get(blurred)
            if len(faces_blur) > 0:
                embeddings_list.append(faces_blur[0].embedding)
        
        if len(embeddings_list) == 0:
            print("‚ùå No face found in target image.")
            return False
        
        self.target_embeddings = embeddings_list
        self.target_name = "TARGET"
        print(f"‚úÖ Target locked! Stored {len(embeddings_list)} reference embeddings.")
        print(f"   üìä Accuracy boost: ~{min(len(embeddings_list) * 2, 100)}% better angle/lighting tolerance")
        return True
    
    @staticmethod
    def rotate_image(image, angle):
        """Rotate image by angle"""
        h, w = image.shape[:2]
        center = (w // 2, h // 2)
        M = cv2.getRotationMatrix2D(center, angle, 1.0)
        return cv2.warpAffine(image, M, (w, h))
    
    @staticmethod
    def adjust_gamma(image, gamma=1.0):
        """Adjust image gamma for brightness variation"""
        inv_gamma = 1.0 / gamma
        table = np.array([((i / 255.0) ** inv_gamma) * 255
                          for i in np.arange(0, 256)]).astype("uint8")
        return cv2.LUT(image, table)
    
    @staticmethod
    def compute_similarity(feat1, feat2):
        """Compute cosine similarity between two embeddings"""
        return np.dot(feat1, feat2) / (np.linalg.norm(feat1) * np.linalg.norm(feat2))
    
    def is_target_match(self, embedding):
        """Check if embedding matches target using multiple reference embeddings"""
        if not self.target_embeddings:
            return False, 0.0
        
        # Optimized: vectorized similarity computation
        similarities = np.array([self.compute_similarity(ref_emb, embedding) 
                                for ref_emb in self.target_embeddings])
        max_sim = np.max(similarities)
        
        return max_sim > RECOGNITION_THRESHOLD, max_sim
    
    def preprocess_frame(self, frame):
        """Optimized preprocessing with caching"""
        # Use cached version if available
        if self.last_preprocessed_frame == self.frame_count:
            return self.preprocessed_cache
        
        # Only preprocess every N frames
        if self.frame_count % PREPROCESS_EVERY_N_FRAMES != 0 and self.preprocessed_cache is not None:
            return self.preprocessed_cache
        
        # Fast histogram equalization
        frame_yuv = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV)
        frame_yuv[:,:,0] = cv2.equalizeHist(frame_yuv[:,:,0])
        frame_enhanced = cv2.cvtColor(frame_yuv, cv2.COLOR_YUV2BGR)
        
        # Cache result
        self.preprocessed_cache = frame_enhanced
        self.last_preprocessed_frame = self.frame_count
        
        return frame_enhanced
    
    def detect_faces_multiscale(self, frame):
        """Optimized multi-scale detection"""
        all_faces = []
        
        # Primary detection
        faces = self.app.get(frame)
        all_faces.extend(faces)
        
        if USE_MULTI_SCALE:
            # Reduced scales for speed while maintaining accuracy
            scales = [0.90, 0.80]
            h, w = frame.shape[:2]
            
            for scale in scales:
                crop_h, crop_w = int(h * scale), int(w * scale)
                start_h, start_w = (h - crop_h) // 2, (w - crop_w) // 2
                
                cropped = frame[start_h:start_h+crop_h, start_w:start_w+crop_w]
                faces_crop = self.app.get(cropped)
                
                for face in faces_crop:
                    face.bbox += np.array([start_w, start_h, start_w, start_h])
                    all_faces.append(face)
        
        unique_faces = self.remove_duplicates(all_faces)
        
        if len(unique_faces) > MAX_FACES_TO_PROCESS:
            unique_faces.sort(key=lambda x: x.det_score, reverse=True)
            unique_faces = unique_faces[:MAX_FACES_TO_PROCESS]
        
        return unique_faces
    
    def detect_faces_tracked(self, frame):
        """Hybrid detection: Full detection periodically, tracking in between"""
        
        # Run full detection every N frames or if no trackers
        should_detect = (
            (self.frame_count - self.last_full_detection_frame) >= DETECTION_INTERVAL or
            not ENABLE_FACE_TRACKING or
            len(self.face_trackers) == 0
        )
        
        if should_detect:
            faces = self.detect_faces_multiscale(frame)
            self.last_full_detection_frame = self.frame_count
            
            # Initialize/update trackers
            if ENABLE_FACE_TRACKING:
                self.face_trackers = []
                for face in faces:
                    tracker = FaceTracker()
                    tracker.init(frame, face.bbox, face)
                    self.face_trackers.append(tracker)
            
            return faces
        
        # Use tracking for intermediate frames (MUCH faster)
        tracked_faces = []
        valid_trackers = []
        
        for tracker in self.face_trackers:
            success, bbox = tracker.update(frame)
            
            # Only keep successful tracks that haven't drifted too long
            if success and tracker.frames_since_update < DETECTION_INTERVAL:
                tracker.face_data.bbox = bbox
                tracked_faces.append(tracker.face_data)
                valid_trackers.append(tracker)
        
        self.face_trackers = valid_trackers
        return tracked_faces
    
    @staticmethod
    def remove_duplicates(faces, iou_threshold=0.5):
        """Optimized duplicate removal"""
        if len(faces) <= 1:
            return faces
        
        def compute_iou(box1, box2):
            x1 = max(box1[0], box2[0])
            y1 = max(box1[1], box2[1])
            x2 = min(box1[2], box2[2])
            y2 = min(box1[3], box2[3])
            
            inter_area = max(0, x2 - x1) * max(0, y2 - y1)
            box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])
            box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])
            
            union_area = box1_area + box2_area - inter_area
            return inter_area / union_area if union_area > 0 else 0
        
        unique_faces = []
        for face in faces:
            is_duplicate = False
            face_to_remove_idx = -1
            
            for idx, unique_face in enumerate(unique_faces):
                if compute_iou(face.bbox, unique_face.bbox) > iou_threshold:
                    if face.det_score > unique_face.det_score:
                        face_to_remove_idx = idx
                        break
                    else:
                        is_duplicate = True
                        break
            
            if face_to_remove_idx >= 0:
                unique_faces.pop(face_to_remove_idx)
                unique_faces.append(face)
            elif not is_duplicate:
                unique_faces.append(face)
        
        return unique_faces
    
    def draw_results(self, frame, faces):
        """Ultra-optimized drawing"""
        target_found = False
        total_faces = len(faces)
        
        for face in faces:
            box = face.bbox.astype(int)
            
            color = (0, 0, 255)
            label = f"{face.det_score:.2f}"
            thickness = 2
            
            if self.target_embeddings:
                is_match, similarity = self.is_target_match(face.embedding)
                
                if is_match:
                    color = (0, 255, 0)
                    label = f"{similarity:.3f}"
                    thickness = 3
                    target_found = True
                    
                    # Simple pulsing (reduced computation)
                    pulse = int(12 * (1 + np.sin(time.time() * 7)))
                    cv2.rectangle(frame, 
                                (box[0]-pulse, box[1]-pulse), 
                                (box[2]+pulse, box[3]+pulse), 
                                (0, 255, 255), 2)
                else:
                    # Skip non-targets in crowd mode
                    continue
            
            # Draw bounding box
            cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), color, thickness)
            
            # Label background
            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            cv2.rectangle(frame, 
                        (box[0], box[1] - label_size[1] - 10), 
                        (box[0] + label_size[0], box[1]), 
                        color, -1)
            
            # Label text
            cv2.putText(frame, label, (box[0], box[1] - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # Draw landmarks only for target
            if face.kps is not None and target_found:
                for point in face.kps.astype(int):
                    cv2.circle(frame, tuple(point), 2, (0, 255, 255), -1)
        
        # Status display
        if self.target_embeddings:
            status_color = (0, 255, 0) if target_found else (0, 0, 255)
            status_text = "TARGET ‚úì" if target_found else "SEARCHING"
            
            cv2.rectangle(frame, (10, 90), (280, 150), (0, 0, 0), -1)
            cv2.rectangle(frame, (10, 90), (280, 150), status_color, 2)
            
            cv2.putText(frame, status_text, (20, 115), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, status_color, 2)
            cv2.putText(frame, f"Faces: {total_faces}", (20, 140), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        return frame
    
    def update_fps(self):
        """Calculate FPS"""
        current_time = time.time()
        fps = 1.0 / (current_time - self.last_time + 1e-6)
        self.last_time = current_time
        self.fps_buffer.append(fps)
        return np.mean(self.fps_buffer)
    
    def draw_ui(self, frame):
        """Minimal UI overlay"""
        fps = self.update_fps()
        
        # FPS display with color coding
        fps_color = (0, 255, 0) if fps > 50 else (0, 255, 255) if fps > 30 else (0, 0, 255)
        cv2.putText(frame, f"FPS: {fps:.1f}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, fps_color, 2)
        
        mode = "TARGET" if self.target_embeddings else "GENERAL"
        mode_color = (0, 255, 0) if self.target_embeddings else (255, 255, 0)
        cv2.putText(frame, mode, (10, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, mode_color, 2)
        
        return frame
    
    def run(self):
        """Main loop - 60 FPS optimized"""
        image_name = input("üìÇ Target image name (or Enter to skip): ").strip()

        if image_name:
            self.load_target(image_name)
        else:
            print("‚ö†Ô∏è No target. Running in General Mode.")
        
        cap = cv2.VideoCapture(CAMERA_ID)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)
        cap.set(cv2.CAP_PROP_FPS, 60)
        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # Minimize lag
        
        if not cap.isOpened():
            print("‚ùå Could not open webcam.")
            return
        
        cv2.namedWindow("Robot Eye", cv2.WINDOW_NORMAL)
        cv2.resizeWindow("Robot Eye", FRAME_WIDTH, FRAME_HEIGHT)
        
        print("üé• Camera Started!")
        print("üöÄ Target: 60 FPS | Current Detection: Every", DETECTION_INTERVAL, "frames")
        print("Controls: q=quit | s=save | r=reload | c=change")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            self.frame_count += 1
            
            # Smart preprocessing (cached)
            frame_processed = self.preprocess_frame(frame)
            
            # Hybrid detection/tracking
            faces = self.detect_faces_tracked(frame_processed)
            
            # Optimized rendering
            frame_display = self.draw_results(frame.copy(), faces)
            frame_display = self.draw_ui(frame_display)
            
            cv2.imshow('Robot Eye', frame_display)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('s'):
                filename = f"capture_{int(time.time())}.jpg"
                cv2.imwrite(filename, frame)
                print(f"üì∏ Saved: {filename}")
            elif key == ord('r') and image_name:
                print("üîÑ Reloading...")
                self.load_target(image_name)
            elif key == ord('c'):
                new_image = input("üìÇ New target: ").strip()
                if new_image:
                    image_name = new_image
                    self.load_target(new_image)
        
        cap.release()
        cv2.destroyAllWindows()
        print("üëã Stopped. Average FPS:", np.mean(self.fps_buffer))


if __name__ == "__main__":
    tracker = OptimizedFaceTracker()
    tracker.run()   